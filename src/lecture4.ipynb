{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "# Lecture 4\n",
    "\n",
    "## The Validation Set Approach\n",
    "\n",
    "Please run the following cell with `Shift+Enter` to see the video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IRdisplay::display_html('<iframe width=\"640\" height=\"360\" src=\"https://tube.switch.ch/embed/33f91644\" frameborder=\"0\" allow=\"fullscreen\"></iframe>')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "Let us generate the artificial dataset from the slides with 150 points in total."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f <- function(x) 0.3 + 2*x - .8*x^2 - .4*x^3\n",
    "data.generator <- function(N = 150) {\n",
    "    x <- rnorm(N)\n",
    "    y <- f(x) + rnorm(N)\n",
    "    data.frame(X = x, Y = y)\n",
    "}\n",
    "set.seed(44)\n",
    "data <- data.generator()\n",
    "plot(data)\n",
    "curve(f, from = -4, to = 4, add = T, col = \"orange\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "Next we split off a test set that we won't touch until the very end and a\n",
    "training set that we will later further divide into training and validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "data.test <- data[101:150,]\n",
    "data <- data[1:100,]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "In the next cell we define the function `fit.and.evaluate` to fit a polynomial\n",
    "model of degree $d$ to the training data and return the training and the\n",
    "validation error. The function `evaluate.split` computes these errors for a\n",
    "given split and all degrees from $d = 1$ to $d = 10$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "fit.and.evaluate <- function(d, train, validat) {\n",
    "    fit <- lm(Y ~ poly(X, d), train)\n",
    "    c(mean((train$Y - predict(fit, train))^2),\n",
    "      mean((validat$Y - predict(fit, validat))^2))\n",
    "}\n",
    "evaluate.split <- function(idx.train) {\n",
    "    d <- seq(1:10)\n",
    "    sapply(d, fit.and.evaluate, data[idx.train,], data[-idx.train,])\n",
    "}\n",
    "set.seed(17)\n",
    "plot(c(), ylab = \"error\", xlab = \"degree\", xlim = c(1, 10), ylim = c(0, 5)) # creates an empty plot\n",
    "for (i in 1:20) { # fit and evaluate for 20 different splits\n",
    "    idx.train <- sample(nrow(data), nrow(data)/2)\n",
    "    res <- evaluate.split(idx.train)\n",
    "    optimal.d <- which.min(res[2,])  # the which.min function finds the argmin of the vector res[2,]\n",
    "    lines(res[1,], type = 'l', lwd = .5, col = 'red')\n",
    "    lines(res[2,], type = 'l', lwd = .5, col = 'blue')\n",
    "    points(optimal.d, res[2,optimal.d], col = 'blue', pch = 19) # mark with a dot the optimal degree\n",
    "}\n",
    "legend(\"topright\", legend = c(\"training\", \"validation\"), col = c(\"red\", \"blue\"), lty = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "We see that the validation set approach finds different degrees of the\n",
    "polynomial depending on the split.\n",
    "\n",
    "In the following two cells we estimate the test error with first a\n",
    "fit on half of the data and then a fit on all data.\n",
    "The minimal test error can be found by looking at the data generation process.\n",
    "What is it's value? Once you know the answer, evaluate the following two cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit1 <- lm(Y ~ poly(X, 3), data[1:50,])\n",
    "mean((data.test$Y - predict(fit1, data.test))^2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit2 <- lm(Y ~ poly(X, 3), data)\n",
    "mean((data.test$Y - predict(fit2, data.test))^2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "You can see that the model fitted on all training data estimates the test error\n",
    "better than the model fitted on only half the data. (Not too surprisingly :))\n",
    "\n",
    "If we only care about making as accurate predictions as possible, we should use\n",
    "all available data to fit the model. In the following cell we combine again the\n",
    "training set and the test set with the function `rbind`, perform a fit on all\n",
    "available data and evaluate the new fit together with the fits from the previous\n",
    "two cells on a really large, newly generated test function to convince ourselves\n",
    "that it is indeed best to fit on all available data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.all <- rbind(data, data.test)\n",
    "fit3 <- lm(Y ~ poly(X, 3), data.all)\n",
    "large.test.data <- data.generator(10^5)\n",
    "sapply(list(fit1, fit2, fit3), function(fit) mean((large.test.data$Y - predict(fit, large.test.data))^2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can now solve the 3 questions on the first page of this week's\n",
    "[quiz](https://moodle.epfl.ch/mod/quiz/view.php?id=1099910).\n",
    "\n",
    "## Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IRdisplay::display_html('<iframe width=\"640\" height=\"360\" src=\"https://tube.switch.ch/embed/39baffeb\" frameborder=\"0\" allow=\"fullscreen\"></iframe>')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "### Leave-One-Out Cross Validation\n",
    "We continue with the example from above. To run cross-validation we define the\n",
    "function `cv.fit.and.evaluate` that takes as first argument the indices of the\n",
    "samples to be left out from training (`idx.leftout`); the validation set is\n",
    "constructed with exactly those samples that are not part of the training set.\n",
    "In the second to last line we provide every index of the data set once as input to\n",
    "the `cv.fit.and.evaluate` function to run leave-one-out cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv.fit.and.evaluate <- function(idx.leftout, data, d = 1) {\n",
    "    fit.and.evaluate(d, data[-idx.leftout,], data[idx.leftout,])[2]\n",
    "}\n",
    "errors <- sapply(1:nrow(data), cv.fit.and.evaluate, data)\n",
    "head(errors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "Now we can average accross all validation errors we obtained in the previous\n",
    "cell to compute $\\mathrm{CV}_{(n)}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean(errors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "We repeat now the steps from above for all degrees $d=1,\\ldots,10$, plot\n",
    "$\\mathrm{CV}_{(n)}$ and mark with a dot the optimal degree.\n",
    "We use a so-called anonymous function in the first line; it is anonymous,\n",
    "because we do not give it a name. If you want to better understand what is\n",
    "happening here, you are adviced to play around a bit, e.g. what do you think\n",
    "will be the result of `sapply(1:4, function(x) x^2 + 1)`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CV.n <- sapply(1:10, function(d) mean(sapply(1:nrow(data), cv.fit.and.evaluate, data, d)))\n",
    "plot(CV.n, type = 'l', col = 'blue', ylim = c(0, 5), lwd = 2, xlab = \"degree\")\n",
    "optimal.d <- which.min(CV.n)\n",
    "points(optimal.d, CV.n[optimal.d], col = 'blue', pch = 19)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "### k-fold Cross Validation\n",
    "\n",
    "In the following cell we first define a function that gives as the index sets\n",
    "for the different folds. In the output you should see that we have 5 times a\n",
    "list of 20 integers: these are the indices of the samples that are in the\n",
    "validation set; all other indices will make up the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CV.k.indices <- function(data, k) {\n",
    "    n <- floor(nrow(data)/k) # compute the size of each fold\n",
    "    ordering <- sample(1:nrow(data), nrow(data)) # reshuffle the indices\n",
    "    lapply(1:k, function(i) ordering[seq((i-1)*n +1, i*n)])\n",
    "}\n",
    "idxs <- CV.k.indices(data, 5)\n",
    "idxs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "In the following cell we run 10 times 5-fold cross-validation to get the figure\n",
    "from the slides."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(c(), xlim = c(1, 10), ylim = c(0, 5), xlab = \"degree\", ylab = \"CV(k)\")\n",
    "for(i in 1:10) {\n",
    "    idxs <- CV.k.indices(data, 5)\n",
    "    CV.k <- sapply(1:10, function(d) mean(sapply(idxs, cv.fit.and.evaluate, data, d)))\n",
    "    lines(CV.k, col = 'blue')\n",
    "    optimal.d <- which.min(CV.k)\n",
    "    points(optimal.d, CV.k[optimal.d], col = 'blue', pch = 19)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "While it may help understanding to code everything oneself, it can also become\n",
    "annoying to repeat the same steps again and again, when you apply machine\n",
    "learning in your daily work. Fortunately, there are quite a few nice libraries\n",
    "that simplify these tasks. One of these libraries that we will start to use more\n",
    "often now, is the `tidymodels` library. It contains the functions\n",
    "`initial_split`, `training`, `testing`, `vfold_cv`, `analysis` and `assessment`\n",
    "that we will use in the cell below to perform the same steps as above in far\n",
    "fewer lines of code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(tidymodels)\n",
    "train_test_split <- initial_split(data.all, prop = 2/3) # split data; 2/3 will be training data\n",
    "data_train <- training(train_test_split) # extract the training set from the split\n",
    "data_test <- testing(train_test_split)\n",
    "validation_data <- vfold_cv(data_train, v = 5) # create the 5 folds\n",
    "tidy_fit_and_evaluate <- function(fold, d) {\n",
    "    fit <- lm(Y ~ poly(X, d), analysis(fold)) # the function `analysis` extracts the training set from the fold (marked blue in the slides)\n",
    "    validation_set <- assessment(fold) # the function `assessment` extracts the validation set from the fold (marked blue in the slides)\n",
    "    mean((validation_set$Y - predict(fit, validation_set))^2)\n",
    "}\n",
    "sapply(1:10, function(d) mean(sapply(validation_data$splits, tidy_fit_and_evaluate, d)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can now solve the questions on the second page of this week's\n",
    "[quiz](https://moodle.epfl.ch/mod/quiz/view.php?id=1099910).\n",
    "\n",
    "## Model Selection with the Akaike Information Criterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IRdisplay::display_html('<iframe width=\"640\" height=\"360\" src=\"https://tube.switch.ch/embed/8ec3bdbc\" frameborder=\"0\" allow=\"fullscreen\"></iframe>')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "The standard `lm` function does not automatically compute the AIC, but the `glm`\n",
    "function does. We use it here with the argument `family = \"gaussian\"` to perform\n",
    "standard linear least-squares regression and return the AIC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "fit.and.aic <- function(d, data) {\n",
    "    fit <- glm(Y ~ poly(X, d), data, family = \"gaussian\")\n",
    "    summary(fit)$aic\n",
    "}\n",
    "aics <- sapply(1:10, fit.and.aic, data)\n",
    "plot(aics, type = \"l\", xlab = \"degree\", ylab = \"AIC\")\n",
    "d <- which.min(aics)\n",
    "points(d, aics[d])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "You can see, that we would have found the optimal degree $d = 3$ also with\n",
    "the AIC criterion.\n",
    "\n",
    "You can now solve the questions on the third page of this week's\n",
    "[quiz](https://moodle.epfl.ch/mod/quiz/view.php?id=1099910).\n",
    "\n",
    "## Example: Find Relevant Predictors with Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IRdisplay::display_html('<iframe width=\"640\" height=\"360\" src=\"https://tube.switch.ch/embed/94316bc2\" frameborder=\"0\" allow=\"fullscreen\"></iframe>')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "We come back here to the artificial data set with the latent cause from last\n",
    "week."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(19)\n",
    "N <- 100\n",
    "z <- runif(N)\n",
    "data <- data.frame(X1 = 0.7*z, X2 = z + .01*rnorm(N),\n",
    "                   X3 = runif(N), Y = rep(0, N))\n",
    "beta <- c(-.8, -.4, 2, -.5)\n",
    "m <- model.matrix(Y ~ ., data)\n",
    "data$Y <- m %*% beta + .1 * rnorm(N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "Let us now run all possible models and print the $R^2$ values and the\n",
    "fitted coefficients. In contrast to the previous section - where we used the AIC to\n",
    "adjust the training error for different flexibilities of the model - we are only\n",
    "interested in the ranking of different models with identical flexibility in the\n",
    "first step of subset selection. This is why we use the $R^2$ values here to find\n",
    "for each number of predictors the best model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "fit.and.print <- function(formula, data) {\n",
    "    fit <- lm(formula, data)\n",
    "    r.squared <- summary(fit)$r.squared\n",
    "    print(formula)\n",
    "    print(r.squared)\n",
    "    print(coef(fit))\n",
    "    r.squared\n",
    "}\n",
    "fit.subsets <- sapply(c(Y ~ 1,\n",
    "                        Y ~ X1, Y ~ X2, Y ~ X3,\n",
    "                        Y ~ X1 + X2, Y ~ X1 + X3, Y ~ X2 + X3,\n",
    "                        Y ~ .), fit.and.print, data)\n",
    "fit.subsets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "You see that the $R^2$ values for formulas `Y ~ X1` and `Y ~ X2` are very close\n",
    "to each other. Likewise, the $R^2$ values for formulas `Y ~ X1 + X3` and `Y ~ X2 + X3` are very similar to each other. The highest $R^2$ value, i.e. the lowest\n",
    "training error has the last model with all predictors.\n",
    "\n",
    "Let us plot the results as a function of the number of predictors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(c(0, 1, 1, 1, 2, 2, 2, 3), fit.subsets,\n",
    "     xlab = \"number of predictors\",\n",
    "     ylab = parse(text = \"R^2\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "Fortunately, also for this task there is a library to help us. The library\n",
    "`leaps` contains the function `regsubsets`. The result we see from the following\n",
    "cell shows which predictors to keep in the best model of a given size. For\n",
    "example the `*` in the first row of the output indicates that the best model\n",
    "with one predictor is the one with `X2`, the best with 2 predictors is the one\n",
    "with `X2` and `X3`. Check, if this is consistent with the results we obtained\n",
    "above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(leaps)\n",
    "reg.fit <- regsubsets(Y ~ ., data)\n",
    "summary(reg.fit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "We can also extract the $R^2$ values for the best performing models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(reg.fit)$rsq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "And the coefficients of the best model with `id = k` predictors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "coef(reg.fit, id = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "Fits obtained with `regsubsets` do unfortunately not have a `predict` function.\n",
    "We can write our own one instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "predict.regsubsets <- function(object, newdata, id, form = as.formula(object$call[[2]])) {\n",
    "    mat = model.matrix(form, newdata)\n",
    "    coefi = coef(object, id=id)\n",
    "    xvars = names(coefi)\n",
    "    mat[,xvars]%*%coefi\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "While the dot `.` often does not have any specific meaning in R, it does have\n",
    "one when defining generic functions for different objects. For example\n",
    "`predict(lm(Y ~ ., data))` actually calls the function `predict.lm`; similarly\n",
    "there is a `predict.glm` function. You can look at all variants of `predict` with\n",
    "`methods(predict)`. Thus, when we write `predict(reg.fit, data, 1)` this will\n",
    "call our new `predict.regsubsets` function.\n",
    "\n",
    "Let us check, if our new predict function computes the right result.\n",
    "Because we know that the best model with 2 predictors is the one with predictors\n",
    "`X2` and `X3`, we compare it to the predictions we obtain with a standard `lm`\n",
    "fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "head(predict(reg.fit, data, 2) - predict(lm(Y ~ X2 + X3, data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "Let us now perform 10-fold cross-validation to find the best number of predictors.\n",
    "We use again the functions form the `tidymodels` library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_data <- vfold_cv(data, v = 10)\n",
    "fit_and_evaluate <- function(fold, formula = Y ~ .) {\n",
    "    fit <- regsubsets(formula, analysis(fold))\n",
    "    valid.set <- assessment(fold)\n",
    "    sapply(seq(1, fit$nvmax - 1),\n",
    "           function(id) mean((valid.set$Y - predict(fit, valid.set, id, formula))^2))\n",
    "}\n",
    "cv.errors <- sapply(validation_data$splits, fit_and_evaluate)\n",
    "cv.errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "Let us now average the errors over the 10 fold to obtain the final result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "rowMeans(cv.errors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the model with 2 predictors is slightly favoured by\n",
    "cross-validation. Thus we have indeed found one of the simplified models with\n",
    "our model selection.\n",
    "\n",
    "You can now solve the questions on the fourth page of this week's\n",
    "[quiz](https://moodle.epfl.ch/mod/quiz/view.php?id=1099910).\n",
    "\n",
    "## Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe width=\"640\" height=\"360\" src=\"https://tube.switch.ch/embed/efa7e9b6\" frameborder=\"0\" allow=\"fullscreen\"></iframe>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "IRdisplay::display_html('<iframe width=\"640\" height=\"360\" src=\"https://tube.switch.ch/embed/efa7e9b6\" frameborder=\"0\" allow=\"fullscreen\"></iframe>')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "### Lasso (L1 regularization)\n",
    "\n",
    "To perform linear regression with L1 regularization we load the library `glmnet`\n",
    "and represent the input data as a matrix and the response as a vector.\n",
    "The `glmnet` function perform linear regression with L1 regularization if\n",
    "`alpha = 1` and L2 regularization if `alpha = 0`. The `lambda` argument sets the\n",
    "size of the allowed area. Here we give it a sequence of 100 points between\n",
    "$10^-2$ and $10$ to perform linear regression with different values of the size\n",
    "of the allowed area."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(glmnet)\n",
    "x <- as.matrix(data[,c(\"X1\", \"X2\", \"X3\")])\n",
    "y <- data$Y\n",
    "lasso.mod <- glmnet(x, y, alpha = 1, lambda = 10^seq(1, -2, length = 100))\n",
    "plot(lasso.mod, \"lambda\", xlab = parse(text = \"Log(lambda)\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "The function `cv.glmnet` performs 10-fold cross-validation to find the optimal\n",
    "value for the parameter `lambda`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv.lasso <- cv.glmnet(x, y, alpha = 1, nfold = 10)\n",
    "plot(cv.lasso)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "Let us finally run the Lasso with the optimal `lambda`. The coefficients found\n",
    "are very similar to the ones found with cross-validated subset selection: again\n",
    "$\\beta_1 = 0$ and the other values are pretty close to the ones found with\n",
    "`coef(lm(Y ~ X2 + X3, data))`; they are just slightly smaller as a result of the\n",
    "L1 regularization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best.lasso <- glmnet(x, y, alpha = 1, lambda = cv.lasso$lambda.min)\n",
    "coef(best.lasso)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can now solve the questions on the last page of this week's\n",
    "[quiz](https://moodle.epfl.ch/mod/quiz/view.php?id=1099910).\n",
    "\n",
    "## Exercises\n",
    "### Conceptual\n",
    "**Q1.** We formulated regularization as a constrained optimization problem with one\n",
    "inequality constraint.  A standard approach to solve constraint optimization\n",
    "problems makes use of Karush-Kuhn-Tucker (KKT) multipliers. For example, to find\n",
    "the minimum of function $f(x)$ under the constraint $g(x) \\leq s$ one can define\n",
    "the loss function $$L(x, \\lambda) = f(x) + \\lambda(g(x) - s)$$ where\n",
    "$\\lambda\\geq0$ is a KKT multiplier.  Minimizing the loss both in $x$ and\n",
    "$\\lambda$ amounts to solving the equations $\\frac{\\partial L}{\\partial x} = f'(x)\n",
    "+ \\lambda g'(x) = 0$ and $\\frac{\\partial L}{\\partial \\lambda} = g(x) - s = 0$,\n",
    "if the solution is on the boundary of the area defined by the inequality\n",
    "constraint; otherwise one can find the solution by simply solving the\n",
    "unconstrained problem, i.e. with $\\lambda = 0$. In this formulation one choses\n",
    "the size $s$ of the allowed area and find $\\lambda$ by solving the equations.\n",
    "\n",
    "Interestingly, the loss function $$L(x) = f(x) + \\lambda\n",
    "g(x)$$ has exactly the same partial derivative in $x$ as $L(x, \\lambda)$ and\n",
    "therefore all critical points of $L(x)$ have corresponding critical\n",
    "points of $L(x,\\lambda)$. Because of this, regularization is often formulated\n",
    "as \"adding a regularization term to the cost function\". For example, given loss\n",
    "function of linear regression $L(\\beta) = \\mathrm{RSS}$ one can define the\n",
    "L1-regularized loss function $L_1(\\beta) = \\mathrm{RSS} + \\lambda\n",
    "\\|\\beta\\|_1$ and choose a value for $\\lambda$ instead of the size $s$ of the\n",
    "allowed area.\n",
    "\n",
    "(a) Argue, why choosing $\\lambda = 0$ in the second formulation is equivalent to\n",
    "choosing $s = \\infty$ in the first formulation.\n",
    "\n",
    "(b) Argue, why choosing $\\lambda = \\infty$ in the second formulation is\n",
    "equivalent to choosing $s = 0$ in the first formulation.\n",
    "\n",
    "**Q2.** Consider a data set with as many data points as predictors $n = p$.\n",
    "Assume $x_{ii} = 1$ and $x_{ij} = 0$ for all $i\\neq j$ and arbitrary values\n",
    "$y_i$. To simplify the problem further we perform regression without an\n",
    "intercept. We would like to study L1- and L2-regularized multiple linear regression.\n",
    "\n",
    "(a) Write the RSS loss once with L1 regularization and once with L2\n",
    "regularization for this setting and the second fomulation of regularization seen\n",
    "in Q1.\n",
    "\n",
    "(b) Show that in the case of L2 regularization the estimated coefficients take\n",
    "the form $\\hat \\beta_j = y_j/(1 + \\lambda)$.\n",
    "\n",
    "(c) Show that in the case of L1 regularization the estimated coefficients take\n",
    "the form $\\hat \\beta_j = y_j - \\lambda/2$, if $y_j > \\lambda/2$,\n",
    "$\\hat \\beta_j = y_j + \\lambda/2$, if $y_j < -\\lambda/2$ and $\\hat \\beta_j = 0$\n",
    "otherwise.\n",
    "\n",
    "(d) Write a brief summary on how the estimated coefficients $\\hat \\beta_j$ are\n",
    "changed relative to the unregularized solution for both kinds of regularization.\n",
    "\n",
    "(e) Compare your solutions with the text in section \"A Simple Special Case\n",
    "for Ridge Regression and the Lasso\" of the text book (page 224).\n",
    "\n",
    "**Q3.** We now review k-fold cross-validation.\n",
    "\n",
    "(a) Explain how k-fold cross-validation is implemented.\n",
    "\n",
    "(b) What are the advantages and disadvantages of k-fold cross-validation\n",
    "relative to:\n",
    "\n",
    "i. The validation set approach?\n",
    "\n",
    "ii. LOOCV?\n",
    "\n",
    "### Applied\n",
    "\n",
    "**Q4.** Create an artificial dataset with 10 points, 4 predictors $X_1, X_2, X_3, X_4$\n",
    "and $Y = X_1 + \\epsilon$ with $\\mathrm{Var}(\\epsilon) = 0.1^2$.\n",
    "\n",
    "(a) Run subset selection and report all $R^2$ values.\n",
    "\n",
    "(b) Which model has the lowest training error?\n",
    "\n",
    "(c) Find with cross-validation the model which has the lowest expected test error.\n",
    "\n",
    "(d) Find with cross-validation and the lasso the best model.\n",
    "\n",
    "**Q5.** In this exercise we work again with the life expectancy dataset.\n",
    "\n",
    "(a) Find with cross-validation the best degree $d$ of polynomial regression with\n",
    "the single predictor GDP and response LifeExpectancy.\n",
    "\n",
    "(b) Find with cross-validated subset selection the best subset of predictors in\n",
    "multiple linear regression with predictors GDP, BMI, Year and Alcohol and\n",
    "response LifeExpectancy.\n",
    "\n",
    "(c) Run L1 and L2 regularized multiple linear regression on the full data set\n",
    "and plot the coefficients as a function of $\\lambda$ for both types of\n",
    "regulization.\n",
    "\n",
    "(d) Run the same task as in (b) with cross-validated L1 regularization.\n",
    "\n",
    "(e) Adapt the subset selection algorithm from the slides to choose among the\n",
    "models $\\mathcal M_k$ with the AIC criterion instead of cross-validation and run\n",
    "the same task as in (b) with AIC as the model comparison method.\n",
    "\n",
    "(optional) R has quite a few built-in data sets. You can get a list of the data\n",
    "sets with the function `data()`. Pick one data set you like. As a running\n",
    "example I will use the \"swiss\" data set, but you can pick another one. Load the\n",
    "data set, e.g. with `data(\"swiss\")`. You can get more information about the data\n",
    "set with `?swiss`. Analyse the data set you picked with the machine learning\n",
    "methods you know already."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.0.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
